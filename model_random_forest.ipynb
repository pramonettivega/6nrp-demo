{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: space-between; align-items: center; margin-bottom: 40px; margin-top: 0;\">\n",
    "    <div style=\"flex: 0 0 auto; margin-left: 0; margin-bottom: 0; margin-top: 0;\">\n",
    "        <img src=\"./pics/UCSD Logo.png\" alt=\"UCSD Logo\" style=\"width: 179px; margin-bottom: 0px; margin-top: 20px;\">\n",
    "    </div>\n",
    "    <div style=\"flex: 0 0 auto; margin-left: auto; margin-bottom: 0; margin-top: 20px;\">\n",
    "        <img src=\"./pics/silvxlabs.png\" alt=\"SilvX Labs Logo\" style=\"width: 200px; margin-bottom: 0px;\">\n",
    "    </div>\n",
    "    <div style=\"flex: 0 0 auto; margin-left: auto; margin-bottom: 0; margin-top: 20px;\">\n",
    "        <img src=\"./pics/sdsclogo-plusname-horiz-red.jpg\" alt=\"San Diego Supercomputer Center Logo\" width=\"300\"/>\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "<h1 style=\"text-align: center; font-size: 48px; margin-top: 0;\">6NRP Demo Data Challenge</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acknowledgment\n",
    "\n",
    "This Jupyter Notebook was authored by Anthony Marcozzi from the New Mexico Consortium. The content, including the code, analysis, and visualizations, reflects the author's expertise and effort in creating an accessible and insightful resource. Proper credit is appreciated if this notebook is shared or adapted for further use.\n",
    "\n",
    "# Base Solution\n",
    "\n",
    "In this notebook we will train simple, univariate random forest models to predict the diameter, species, and crown base height of a tree using only an observation on the tree's height. For training data we'll utilize the California daatabase from the Forest Inventory and Analysis (FIA) database. \n",
    "\n",
    "Random forests are a straightforward modeling approach based on voting from a large number of decision trees. In this notebook we will use a [prebuilt model from scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html) rather than programming our own. \n",
    "There's no background knolwedge on what random forest models are or how they work required, but there are a lot of good resources out there for learning more. \n",
    "Some recommended resources are listed below:\n",
    "\n",
    "1) https://builtin.com/data-science/random-forest-algorithm\n",
    "2) https://developers.google.com/machine-learning/decision-forests/random-forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import matplotlib.colors as mcolors\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the detected trees from the ALS data into a geopandas dataframe\n",
    "lidar_trees = pd.read_csv(DATA_PATH / 'ttops.csv')\n",
    "lidar_trees = gpd.GeoDataFrame(lidar_trees, geometry=gpd.points_from_xy(lidar_trees.y, lidar_trees.x), crs='EPSG:4326')\n",
    "\n",
    "# Load the FIA data\n",
    "fia_ca_plot_table = pd.read_csv(DATA_PATH / 'fia' / 'CA_PLOT.csv', low_memory=False)\n",
    "fia_ca_tree_table = pd.read_csv(DATA_PATH / 'fia' / 'CA_TREE.csv', low_memory=False)\n",
    "fia_ref_species_table = pd.read_csv(DATA_PATH / 'fia' / 'REF_SPECIES.csv')\n",
    "\n",
    "# Filter the PLOT table for the ECOSUBCD\n",
    "fia_ca_plot_table = fia_ca_plot_table[fia_ca_plot_table['ECOSUBCD'] == \"M261Ej\"]\n",
    "\n",
    "# Merge the PLOT and TREE tables\n",
    "trees_fia = pd.merge(fia_ca_tree_table, fia_ca_plot_table, left_on='PLT_CN', right_on='CN')\n",
    "\n",
    "# Create a dictionary mapping SPCD to COMMON_NAME\n",
    "spcd_to_common_name = dict(zip(fia_ref_species_table['SPCD'], fia_ref_species_table['COMMON_NAME']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Tree Variables\n",
    "\n",
    "Next, let's use the FIA data as training data for our random forest model. \n",
    "We will train a different model for each variable that we are interested in predicting. \n",
    "This means that we will have a model to predict diameter from height, a second model to predict species from height, and a third model to predict crown base height from total height.\n",
    "\n",
    "Student implementations can look at different approaches including models that predict multiple variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diameter from height\n",
    "\n",
    "Our first random forest model will take in height (HT) as input and produce diameter (DIA) as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and test sets\n",
    "independent_variables = [\"HT\"]\n",
    "dependent_variable = \"DIA\"\n",
    "include_variables = independent_variables + [dependent_variable]\n",
    "trees_train, trees_test = train_test_split(trees_fia[include_variables].dropna(), test_size=0.2)\n",
    "print(f\"Training set size: {len(trees_train)}\")\n",
    "print(f\"Test set size: {len(trees_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model_ht = RandomForestRegressor()\n",
    "model_ht.fit(trees_train[independent_variables], trees_train[dependent_variable])\n",
    "\n",
    "# Compute R^2 and RMSE using the test set\n",
    "print(f\"Model R^2: {model_ht.score(trees_test[independent_variables], trees_test[dependent_variable]):.2f}\")\n",
    "print(f\"Model RMSE: {((model_ht.predict(trees_test[independent_variables]) - trees_test[dependent_variable])**2).mean()**0.5:.2f} inches\")\n",
    "\n",
    "\n",
    "# Compare the predicted diameter to the actual diameter.\n",
    "fig, ax = plt.subplots()\n",
    "trees_test[\"predicted_diameter\"] = model_ht.predict(trees_test[independent_variables])\n",
    "trees_test.plot.scatter(x=\"DIA\", y=\"predicted_diameter\", ax=ax)\n",
    "upper_dia_limit = max(trees_test[\"DIA\"].max(), trees_test[\"predicted_diameter\"].max()) + 1\n",
    "ax.plot([0, upper_dia_limit], [0, upper_dia_limit], color='red')\n",
    "ax.set_xlabel(\"Actual Diameter (in)\")\n",
    "ax.set_ylabel(\"Predicted Diameter (in)\")\n",
    "ax.set_title(\"Validation Data Diameter Prediction\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's pretty good for a simple model! Accuracy decreases as diameter increases, but up to around 30 inches it is quite accurate. It may be worth investigating approaches for outlier detection and removal. For example, maybe we can improve model performance by only considering diameter estimates in a certain range. Consider investigating the diameter range of the validation data to further constrain the problem.\n",
    "\n",
    "Next, let's use our new model to predict the diameters using the heights we observed from the ALS LIDAR data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User our new model to predict the diameter of the trees detected in the ALS data\n",
    "lidar_trees[\"predicted_diameter\"] = model_ht.predict(lidar_trees[independent_variables])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the predicted diameter\n",
    "fig, ax = plt.subplots()\n",
    "lidar_trees.plot.scatter(x=\"HT\", y=\"predicted_diameter\", ax=ax)\n",
    "ax.set_xlabel(\"Height (ft)\")\n",
    "ax.set_ylabel(\"Predicted Diameter (in)\")\n",
    "ax.set_title(\"Independence Lake Tree Diameter Prediction\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SPCD (Species code) from height\n",
    "\n",
    "Species code, or SPCD, is a numeric identifier for tree species across the United States. Tree species is an enormously important characteristic for making predictions about tree biomass, carbon content, size, and more. Unfortunately, we don't learn tree species from the ALS acquistion data so we want to try and predict it using a model trained on FIA data. In this example, we train a simple random forest classifer to predict trees species based just on the height of the tree. Let's see how well this simple model performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and test sets\n",
    "independent_variables = [\"HT\"]\n",
    "dependent_variable = \"SPCD\"\n",
    "include_variables = independent_variables + [dependent_variable]\n",
    "trees_train, trees_test = train_test_split(trees_fia[include_variables].dropna(), test_size=0.2)\n",
    "print(f\"Training set size: {len(trees_train)}\")\n",
    "print(f\"Test set size: {len(trees_test)}\")\n",
    "\n",
    "# Train the model\n",
    "model_spcd = RandomForestClassifier()\n",
    "model_spcd.fit(trees_train[independent_variables], trees_train[dependent_variable])\n",
    "\n",
    "# Evaluate classification accuracy\n",
    "unique_species = sorted(trees_test[dependent_variable].unique())\n",
    "species_names = [spcd_to_common_name.get(spcd, f\"Unknown ({spcd})\") for spcd in unique_species]\n",
    "report = classification_report(trees_test[dependent_variable], model_spcd.predict(trees_test[independent_variables]), zero_division=0, target_names=species_names)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So how did we do? We performed slightly better than taking a random guess across the four most common species, but with an f1-score of 0.35 there is a lot of room for improvement.\n",
    "\n",
    "Let's take a look at the confusion matrix and see if there are any obvious errors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(trees_test[dependent_variable], model_spcd.predict(trees_test[independent_variables]))\n",
    "display = ConfusionMatrixDisplay(cm, display_labels=species_names)\n",
    "display.plot(cmap='Blues', values_format='d')\n",
    "plt.xticks(rotation=90, ha='right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the confusion matrix has identified some common areas of confusion for our model. The model frequently mistakes white for for jeffrey pine, california red fir for white fir and jeffrey pine, jeffrey pine for white fir, and ponderosa pine for jeffrey pine.\n",
    "\n",
    "What can we do to our model to improve predictions? Are there additional variables that you can think of that would help with the prediction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User our new model to predict the SPCD of the trees detected in the ALS data\n",
    "lidar_trees[\"predicted_spcd\"] = model_spcd.predict(lidar_trees[independent_variables])\n",
    "lidar_trees['predicted_species_name'] = lidar_trees['predicted_spcd'].apply(lambda x: spcd_to_common_name.get(x, f\"Unknown ({x})\"))\n",
    "\n",
    "# Create a histogram of the predicted species\n",
    "fig, ax = plt.subplots()\n",
    "lidar_trees[\"predicted_species_name\"].value_counts().plot(kind='bar', ax=ax)\n",
    "ax.set_xlabel(\"Species\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "ax.set_title(\"Independence Lake Tree Species Prediction\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Crown Base Height (CBH) from Height\n",
    "\n",
    "Crown base height (CBH), sometimes called live crown base height, is a measurment of how far above the ground the crown of the tree is. You can think of this as if you stood under a tree and stretched and stretched until your fingertips touch leaves or needles. How far you have to stretch (including your Go-Go-Gadget arm extenders) is the crown base height. \n",
    "\n",
    "Like species code, this is an important measurement because it tells us things like how likely a fire is to move from the surface into the tree, or how much foliage is in the crown. However, also like species code, we can't learn this from the ALS data and it is a difficult thing to predict. But, let's start simple and train a random forest model to predict crown base height just from the height of the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and test sets\n",
    "trees_fia[\"CBH\"] = trees_fia[\"HT\"] * (1 - trees_fia[\"CR\"] / 100)\n",
    "independent_variables = [\"HT\"]\n",
    "dependent_variable = \"CBH\"\n",
    "include_variables = independent_variables + [dependent_variable]\n",
    "trees_train, trees_test = train_test_split(trees_fia[include_variables].dropna(), test_size=0.1)\n",
    "print(f\"Training set size: {len(trees_train)}\")\n",
    "print(f\"Test set size: {len(trees_test)}\")\n",
    "\n",
    "# Train the model\n",
    "model_cbh = RandomForestRegressor()\n",
    "model_cbh.fit(trees_train[independent_variables], trees_train[dependent_variable])\n",
    "\n",
    "# Evaluate model performance\n",
    "print()\n",
    "print(f\"Model R^2: {model_cbh.score(trees_test[independent_variables], trees_test[dependent_variable]):.2f}\")\n",
    "print(f\"Model RMSE: {((model_cbh.predict(trees_test[independent_variables]) - trees_test[dependent_variable])**2).mean()**0.5:.2f} feet\")\n",
    "\n",
    "# Compare the predicted CBH to the actual CBH.\n",
    "fig, ax = plt.subplots()\n",
    "trees_test[\"predicted_cbh\"] = model_cbh.predict(trees_test[independent_variables])\n",
    "trees_test.plot.scatter(x=\"CBH\", y=\"predicted_cbh\", ax=ax)\n",
    "upper_cbh_limit = max(trees_test[\"CBH\"].max(), trees_test[\"predicted_cbh\"].max()) + 1\n",
    "ax.plot([0, upper_cbh_limit], [0, upper_cbh_limit], color='red')\n",
    "ax.set_xlabel(\"Actual CBH (ft)\")\n",
    "ax.set_ylabel(\"Predicted CBH (ft)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the R^2 suggests a reasonable fit to our model, the high RMSE suggests that there is a lot of work to be done on this metric. Unlike the relationship between height and diameter, which is often modeled as a simple exponential relationship, we tend to think of crown base height as more complicated. Live crown base height is often impacted by things like light availability, neighboring trees, and other landscape characteristics. Maybe there are other things from the FIA database, or from external data sources, that we can incorporate into the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User our new model to predict the CBH of the trees detected in the ALS data\n",
    "lidar_trees[\"predicted_cbh\"] = model_cbh.predict(lidar_trees[independent_variables])\n",
    "\n",
    "# Plot the predicted CBH\n",
    "fig, ax = plt.subplots()\n",
    "lidar_trees.plot.scatter(x=\"HT\", y=\"predicted_cbh\", ax=ax)\n",
    "ax.set_xlabel(\"Height (ft)\")\n",
    "ax.set_ylabel(\"Predicted CBH (ft)\")\n",
    "ax.set_title(\"Independence Lake Tree CBH Prediction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot sampled trees on the map with our new predicted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the predicted diameter to the folium map\n",
    "trees_sampled = lidar_trees.sample(10000)\n",
    "\n",
    "# Get unique species names\n",
    "species_names = sorted(trees_sampled['predicted_species_name'].unique())\n",
    "\n",
    "# Create a color map based on unique species names using tab20\n",
    "tab20 = plt.colormaps['tab20']\n",
    "color_dict = {species_name: mcolors.to_hex(tab20(i % 20)) for i, species_name in enumerate(species_names)}\n",
    "\n",
    "# Create the map\n",
    "fmap = folium.Map(location=[trees_sampled.y.mean(), trees_sampled.x.mean()], zoom_start=15)\n",
    "\n",
    "# Add the tile layer\n",
    "tile = folium.TileLayer(\n",
    "    tiles='https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}',\n",
    "    attr='esri').add_to(fmap)\n",
    "\n",
    "# Add markers for each tree\n",
    "for idx, row in trees_sampled.iterrows():\n",
    "    folium.CircleMarker(\n",
    "        location=(row[\"y\"], row[\"x\"]),\n",
    "        radius=3,\n",
    "        weight=2,\n",
    "        color=color_dict[row['predicted_species_name']],\n",
    "        fill=True,\n",
    "        fillColor=color_dict[row['predicted_species_name']],\n",
    "        fillOpacity=0.7,\n",
    "        popup=f\"<b>Height:</b> {row.HT:.2f}ft<br><b>Diameter:</b> {row.predicted_diameter:.2f}in<br><b>Species Code:</b> {row.predicted_species_name}\",\n",
    "    ).add_to(fmap)\n",
    "\n",
    "# Display the map\n",
    "fmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's use our model to make predictions on a set of validation data. Field crews made around 300 tree observations and measured the quantities that we are interested in predicting: diameter, species code, and crown base height.\n",
    "\n",
    "We'll take 25% of that data as our \"validation\" data, and the remaining 75% of the data will be used as \"evalutation\" data to evaluate student submissions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the validation data\n",
    "validation_data = pd.read_csv(DATA_PATH / 'validation_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename tree_ht to HT\n",
    "validation_data.rename(columns={'tree_ht': 'HT'}, inplace=True)\n",
    "\n",
    "# Convert HT from meters to feet\n",
    "validation_data[\"HT\"] *= 3.28084\n",
    "\n",
    "# Rename tree_dbh to DIA\n",
    "validation_data.rename(columns={'tree_dbh': 'DIA'}, inplace=True)\n",
    "\n",
    "# Convert DIA from centimeters to inches\n",
    "validation_data[\"DIA\"] *= 0.393701\n",
    "\n",
    "# Rename tree_htlcb to CBH\n",
    "validation_data.rename(columns={'tree_htlcb': 'CBH'}, inplace=True)\n",
    "\n",
    "# Convert CBH from meters to feet\n",
    "validation_data[\"CBH\"] *= 3.28084\n",
    "\n",
    "# Combine the Genus and Species columns in REF_SPECIES and use the tree_sp_scientific_name column to find the SPCD\n",
    "fia_ref_species_table['SPECIES_NAME'] = fia_ref_species_table['GENUS'] + ' ' + fia_ref_species_table['SPECIES']\n",
    "validation_data[\"SPCD\"] = validation_data[\"tree_sp_scientific_name\"].apply(lambda x: fia_ref_species_table[fia_ref_species_table['SPECIES_NAME'] == x]['SPCD'].values[0])\n",
    "\n",
    "# Drop all columns except HT, DIA, CBH, and SPCD\n",
    "validation_data = validation_data[[\"HT\", \"DIA\", \"CBH\", \"SPCD\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the diameter of the validation data\n",
    "validation_data[\"predicted_diameter\"] = model_ht.predict(validation_data[[\"HT\"]])\n",
    "\n",
    "# Compute RMSE for the diameter prediction\n",
    "dia_rmse = ((validation_data[\"DIA\"] - validation_data[\"predicted_diameter\"])**2).mean()**0.5\n",
    "print(f\"Diameter RMSE: {dia_rmse:.2f} inches\")\n",
    "\n",
    "# Compare the predicted diameter to the actual diameter.\n",
    "fig, ax = plt.subplots()\n",
    "validation_data.plot.scatter(x=\"DIA\", y=\"predicted_diameter\", ax=ax)\n",
    "upper_dia_limit = max(validation_data[\"DIA\"].max(), validation_data[\"predicted_diameter\"].max()) + 1\n",
    "ax.plot([0, upper_dia_limit], [0, upper_dia_limit], color='red')\n",
    "ax.set_xlabel(\"Actual Diameter (in)\")\n",
    "ax.set_ylabel(\"Predicted Diameter (in)\")\n",
    "ax.set_title(\"Validation Data Diameter Prediction\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the species of the validation data\n",
    "validation_data[\"predicted_spcd\"] = model_spcd.predict(validation_data[[\"HT\"]])\n",
    "\n",
    "# Compute the classification accuracy\n",
    "report = classification_report(validation_data[\"SPCD\"], validation_data[\"predicted_spcd\"], zero_division=0)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the CBH of the validation data\n",
    "validation_data[\"predicted_cbh\"] = model_cbh.predict(validation_data[[\"HT\"]])\n",
    "\n",
    "# Compute RMSE for the CBH prediction\n",
    "cbh_rmse = ((validation_data[\"CBH\"] - validation_data[\"predicted_cbh\"])**2).mean()**0.5\n",
    "print(f\"CBH RMSE: {cbh_rmse:.2f} feet\")\n",
    "\n",
    "# Compare the predicted CBH to the actual CBH.\n",
    "fig, ax = plt.subplots()\n",
    "validation_data.plot.scatter(x=\"CBH\", y=\"predicted_cbh\", ax=ax)\n",
    "upper_cbh_limit = max(validation_data[\"CBH\"].max(), validation_data[\"predicted_cbh\"].max()) + 1\n",
    "ax.plot([0, upper_cbh_limit], [0, upper_cbh_limit], color='red')\n",
    "ax.set_xlabel(\"Actual CBH (ft)\")\n",
    "ax.set_ylabel(\"Predicted CBH (ft)\")\n",
    "ax.set_title(\"Validation Data CBH Prediction\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "For final evaluation of entries to the data challenge we will use the remaining 75% of the field data collected around Independence Lake to assess model accuracy. For this assesment, students are expected to provide a \"submission.csv\" file with the following additional columns:\n",
    "\n",
    "- DIA\n",
    "- SPCD\n",
    "- CBH\n",
    "\n",
    "In order to assess model accuracy we will compute the following metrics between your predictions and the actual observed values:\n",
    "\n",
    "- RMSE for DIA and CBH\n",
    "- F1 score for SPCD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the evaluation data\n",
    "evaluation_data = pd.read_csv(DATA_PATH / 'evaluation_data.csv')\n",
    "\n",
    "# Rename tree_ht to HT\n",
    "evaluation_data.rename(columns={'tree_ht': 'HT'}, inplace=True)\n",
    "\n",
    "# Convert HT from meters to feet\n",
    "evaluation_data[\"HT\"] *= 3.28084\n",
    "\n",
    "# Predict the diameter of the evaluation data using the HT model\n",
    "evaluation_data[\"DIA\"] = model_ht.predict(evaluation_data[[\"HT\"]])\n",
    "\n",
    "# Predict the species of the evaluation data using the HT model\n",
    "evaluation_data[\"SPCD\"] = model_spcd.predict(evaluation_data[[\"HT\"]])\n",
    "\n",
    "# Predict the CBH of the evaluation data using the HT model\n",
    "evaluation_data[\"CBH\"] = model_cbh.predict(evaluation_data[[\"HT\"]])\n",
    "\n",
    "# Save the evaluation data to a CSV file named submission.csv\n",
    "evaluation_data.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_data[]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "2024 Challenge",
   "language": "python",
   "name": "challenge"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
